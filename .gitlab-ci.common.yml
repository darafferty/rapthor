# Copyright (C) 2021 ASTRON (Netherlands Institute for Radio Astronomy)
# SPDX-License-Identifier: GPL-3.0-or-later

# This file contains the common parts of both the Astron and SKA pipelines of
# IDG. The yml files for those pipelines include this file.

workflow:
  rules:
    # Don't create a pipeline if it's a commit pipeline on a branch having an open merge request
    - if: $CI_PIPELINE_SOURCE == "push" && $CI_COMMIT_BRANCH && $CI_OPEN_MERGE_REQUESTS
      when: never
    - when: always

stages:
  - versioning
  - prepare
  - build
  - linting
  - test
  - publish
  - pages
  - documentation
  # Since Astron GitLab does not support 'needs' between jobs in the same stage,
  # add an extra documentation stage
  - documentation-publish

# This job stores creates environment variables that are used in other jobs,
# including their definitions, via a 'dotenv' report artifact.
# A job that uses these variables has to include "versioning" in its "needs",
# even if it indirectly depends on "versioning" via another job!
# The 'IMAGE' variables allow reusing docker images between different pipelines.
# Since the GPU image also depends on IDG itself, reusing it makes no sense.
versioning:
  stage: versioning
  image: bitnami/git
  script:
    # Unshallowing ensures that 'git describe' works
    - git fetch --unshallow
    - echo IDG_VERSION=$(git describe --tags --dirty) > versions.env
    - echo BASE_IMAGE=${CI_REGISTRY_IMAGE}/base:$(git log -n 1 --pretty=format:%H -- docker/ubuntu_20_04_base) >> versions.env
    - echo INTEGRATION_IMAGE=${CI_REGISTRY_IMAGE}/integration:$(git log -n 1 --pretty=format:%H -- docker/ubuntu_20_04_integration) >> versions.env
    - echo GPU_IMAGE=${CI_REGISTRY_IMAGE}/gpu:${CI_COMMIT_SHORT_SHA} >> versions.env
    - cat versions.env
  artifacts:
    reports:
      dotenv: versions.env

.prepare:
  stage: prepare
  needs: ["versioning"]
  image: docker:20.10
  services:
    - docker:20.10-dind
  before_script:
    - echo $CI_REGISTRY_PASSWORD | docker login -u $CI_REGISTRY_USER --password-stdin $CI_REGISTRY
  script:
    - |
      if ! docker manifest inspect $DOCKER_IMAGE > /dev/null; then
        for label in $DOCKER_ENV_LABELS; do
          # This image has sh, not bash, so ${!label} and '+=' don't work.
          content=$(eval "echo \"\$${label}\"")
          DOCKER_BUILD_ARG="${DOCKER_BUILD_ARG} --label ${label}=\"${content}\""
        done
        # sh -c "xxx" properly expands $DOCKER_BUILD_ARG.
        sh -c "docker build $DOCKER_BUILD_ARG --tag $DOCKER_IMAGE -f $DOCKER_FILE ."
        docker push $DOCKER_IMAGE
      fi
  # Skip the job if there are no changes to the Docker file. This shortcut only
  # works for push and merge request jobs.
  # A manual pipeline run will thus create missing docker images.
  rules:
    - changes:
      - $DOCKER_FILE

# Create and push the base image to the gitlab registry, if it does not exist.
prepare-base:
  extends: .prepare
  variables:
    DOCKER_IMAGE: $BASE_IMAGE
    DOCKER_FILE: ./docker/ubuntu_20_04_base

# Template for jobs that depend on the optional prepare-base job.
.needs-base:
  needs:
    - job: versioning
    - job: prepare-base
      optional: true
  image: $BASE_IMAGE

# Create and push the integration image to the gitlab registry, if it does not exist.
prepare-integration:
  extends: .prepare
  variables:
    DOCKER_IMAGE: $INTEGRATION_IMAGE
    DOCKER_FILE: ./docker/ubuntu_20_04_integration

format:
  extends: .needs-base
  stage: linting
  script:
    - ./scripts/run-format.sh

build-python:
  extends: .needs-base
  stage: build
  script:
    - mkdir build
    - cd build
    - cmake -DBUILD_WITH_PYTHON=ON ..
    - make install -j4

build-release:
  extends: .needs-base
  stage: build
  script:
    - mkdir build
    - cd build
    - cmake ..
    - make install -j4

build-debug:
  extends: .needs-base
  stage: build
  script:
    - mkdir build
    - cd build
    - cmake .. -DCMAKE_BUILD_TYPE=Debug
    - make install -j4

build-package:
  extends: .needs-base
  stage: build
  script:
    - mkdir idg_package
    - mkdir build
    - cd build
    - git fetch --unshallow # We need to unshallow for the tags (setting GIT_DEPTH is not good enough)
    - cmake -DBUILD_PACKAGES=On ..
    - make -j4
    - make package
    - mv $(ls -1 *.deb) ../idg_package/
  artifacts:
    paths:
    - idg_package/
  rules:
    # The package is built only during a merge_request_event, a merge to master,
    # or when the pipeline is triggered by a tag event.
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
    - if: '$CI_COMMIT_BRANCH == "master"'
    - if: '$CI_COMMIT_TAG'
    - if: '$UPLOAD_PACKAGE'

test-unit:
  extends: .needs-base
  stage: test
  before_script:
    - pip3 install pytest h5py
  script:
    - mkdir -p build
    - cd build
    # Use a Release build, since the unit tests will timeout with a Debug build.
    - cmake .. -DCMAKE_CXX_FLAGS="-coverage" -DCMAKE_EXE_LINKER_FLAGS="-coverage" -DCMAKE_BUILD_TYPE=Release -DBUILD_TESTING=On -DBUILD_WITH_PYTHON=On
    - make install -j4
    - ctest -j8 --output-on-failure -L 'unit|bin_cxx'
    # Capture coverage
    - gcovr -r .. -e '.*/tests/.*' -e '.*/CompilerIdCXX/.*' -e '.*/external/.*' --json run-unit.json --xml coverage.xml
    - gcovr --add-tracefile run-unit.json
  after_script:
    - mkdir -p build/reports
    - ./scripts/junit-merge.py build/reports/unit-tests.xml $(find build -name unittest_*.xml)
    - mv build/coverage.xml build/reports/code-coverage.xml
  artifacts:
    paths:
      - build/reports
      - build/run-unit.json
    reports:
      junit: build/reports/unit-tests.xml
      cobertura: build/reports/code-coverage.xml

# Notes for all integration test jobs:
# - allow_failure is true, since the job will fail when IDG has breaking API
#   changes and WSClean/DP3 have not incorporated those changes yet.
# - Always use the most recent WSClean/DP3 master, instead of a fixed version:
#   - EveryBeam may change, which will require the latest WSclean/DP3.
#   - When the IDG API itself changes, use the latest WSClean/DP3 ASAP.
# - Since the IDG repo should not have (circular) dependencies on WSClean and
#   DP3, we want to run these jobs elsewhere in the future. See AST-653.
test-integration:
  stage: test
  needs:
    - job: versioning
    - job: prepare-integration
      optional: true
  allow_failure: true
  image: $INTEGRATION_IMAGE
  before_script:
    # Install IDG
    - mkdir /opt/idg && mkdir -p build
    - cd build
    - cmake -DBUILD_TESTING=ON -DCMAKE_BUILD_TYPE=Release -DBUILD_PACKAGES=On -DWRITE_OUT_SCALAR_BEAM=ON -DBUILD_WITH_PYTHON=ON -DCMAKE_INSTALL_PREFIX=/opt/idg ..
    - make install -j4
    # Compile against wsclean
    - mkdir /wsclean && cd /wsclean && git clone https://gitlab.com/aroffringa/wsclean.git src
    - mkdir build && cd build
    - cmake -DCMAKE_PREFIX_PATH=/opt/idg -DCMAKE_INSTALL_PREFIX=/usr ../src
    - make install -j4
    - cd $CI_PROJECT_DIR && rm -rf /wsclean
    # Install dp3
    - mkdir /dp3 && cd /dp3 && git clone https://git.astron.nl/RD/dp3.git src
    - mkdir build && cd build
    - cmake -DBUILD_PACKAGES=On -DCMAKE_INSTALL_PREFIX=/usr ../src
    - make install -j4
    - cd $CI_PROJECT_DIR && rm -rf /dp3
  script:
    # Return to idg build directory to run tests
    - cd build
    - ctest --output-on-failure -L integration
  after_script:
    # Collect junit xml reports
    - mkdir -p build/reports
    - mv $(find build/ -name test_*.xml) build/reports/
  artifacts:
    reports:
      junit: build/reports/test_*.xml

# Building documentation happens for all branches, which allows browsing.
# Publishing documentation only happens for the master branch on the Astron repo.
documentation-build:
  extends: .needs-base
  stage: documentation
  script:
    - apt update && apt install -y doxygen
    - python3 -m pip install numpy sphinx breathe sphinx-rtd-theme myst-parser
    - mkdir -p build && cd build
    - cmake -DBUILD_WITH_PYTHON=ON ..
    - make install -j4
    - make doc
  artifacts:
    paths:
    - build/doc/html
